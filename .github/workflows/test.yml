name: Test Suite

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

# Prevent auto-cancellation of running workflows when new commits are pushed
# This ensures test splits actually run to completion instead of being skipped
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

env:
  POETRY_VERSION: "2.2.1"
  PYTHON_VERSION: "3.12"
  CACHE_VERSION: "0.1.5"

jobs:
  # =============================================================================
  # JOB ORDERING RATIONALE (Fail-Fast Optimization)
  # =============================================================================
  #
  # Phase 1 - Quick Validation (parallel, ~2-3 min):
  #   - lint: Code quality (ruff format, ruff check, mypy strict)
  #   - pyright: Type checking (complementary to mypy)
  #   - exports-validation: __all__ exports validation
  #   - docs-validation: Documentation link validation
  #   - node-purity-check: Declarative node purity guarantees
  #   - mypy-validation-scripts: Type check validation scripts
  #   - core-infra-boundary: Transport/I/O import validation (ADR-005)
  #   - enum-governance: Enum architectural standards validation (OMN-1313)
  #
  # Phase 2 - Full Test Suite (after Phase 1 completes):
  #   - test-parallel: 20 splits of full test suite (~3 min each)
  #     Depends on: lint, pyright, exports-validation
  #     This ensures type errors and lint failures are caught BEFORE
  #     spawning 20 parallel test runners (saves ~60 runner-minutes on failure)
  #
  # Phase 3 - Aggregation:
  #   - test-summary: Aggregates all job results
  #
  # This ordering ensures:
  #   1. Fast feedback on code quality issues (type errors, lint, exports)
  #   2. No wasted compute on test splits when validation fails
  #   3. All Phase 1 jobs run in parallel for speed
  # =============================================================================

  # Parallel test execution - split into 20 groups for speed and memory management
  # Split strategy rationale:
  #   - 12,198 total tests / 20 splits = ~610 tests/split
  #   - Target: 1.5-3 minutes per split (prevents runner timeouts/cancellations)
  #   - 20x parallelization speedup vs sequential execution
  #   - Increased from 16 to 20 splits to eliminate Split 10 timeout issues
  #   - Shorter per-split runtime reduces probability of external runner shutdown
  #
  # Dependency rationale (fail-fast optimization):
  #   - lint: Catches formatting, linting, and mypy errors early
  #   - pyright: Catches type errors that mypy might miss
  #   - exports-validation: Ensures __all__ exports are valid before tests
  #   These 3 jobs run in parallel (~3 min total) and must all pass before
  #   spawning 20 test runners. This saves ~60 runner-minutes on validation failures.
  test-parallel:
    name: Tests (Split ${{ matrix.split }}/20)
    needs: [lint, pyright, exports-validation]
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        split: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ env.POETRY_VERSION }}
          virtualenvs-create: true
          virtualenvs-in-project: true

      # Note: omnibase_spi is now public - no auth required

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: >-
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/poetry.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}-${{ env.CACHE_VERSION }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: |
          poetry install --no-interaction --no-root || {
            echo "❌ Dependency install failed"
            exit 1
          }

      - name: Install project
        run: |
          poetry install --no-interaction || {
            echo "❌ Project install failed"
            exit 1
          }

      - name: Run test split ${{ matrix.split }}/20
        run: |
          poetry run pytest tests/ \
            --splits 20 \
            --group ${{ matrix.split }} \
            -n auto \
            --timeout=60 \
            --timeout-method=thread \
            --tb=short \
            --junitxml=junit-${{ matrix.split }}.xml
          # Per-test timeout: 60 seconds prevents infinite hangs
          #   - Longest test: ~30 seconds (2x safety margin)
          #   - Thread method: Avoids signal handler issues in parallel execution
          #   - No false positives observed at this threshold
          # All splits use -n auto (full parallelism) - shorter splits reduce
          # resource pressure and runner cancellation probability
          # Note: Coverage collection disabled - use local pytest-cov for coverage reports

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.split }}
          path: junit-${{ matrix.split }}.xml
          retention-days: 7

  # Phase 1 validation job - runs in parallel with pyright, exports-validation
  # Must complete before test-parallel starts (fail-fast optimization)
  lint:
    name: Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ env.POETRY_VERSION }}
          virtualenvs-create: true
          virtualenvs-in-project: true

      # Note: omnibase_spi is now public - no auth required

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: >-
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/poetry.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}-${{ env.CACHE_VERSION }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root

      - name: Install project
        run: poetry install --no-interaction

      - name: Check ruff formatting
        run: poetry run ruff format --check src/ tests/

      - name: Check ruff linting (includes import sorting)
        run: poetry run ruff check src/ tests/

      - name: Run mypy type checking (strict)
        run: poetry run mypy src/omnibase_core

  # Phase 1 validation job - runs in parallel with lint, exports-validation
  # Must complete before test-parallel starts (fail-fast optimization)
  # Pyright complements mypy (in lint job) - catches different type error categories
  pyright:
    name: Pyright Type Checking
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ env.POETRY_VERSION }}
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: >-
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/poetry.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}-${{ env.CACHE_VERSION }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root

      - name: Install project
        run: poetry install --no-interaction

      - name: Run pyright type checking
        run: poetry run pyright src/omnibase_core

  # Phase 1 validation job - runs in parallel with lint, pyright
  # Must complete before test-parallel starts (fail-fast optimization)
  # Quick check (~5 min) ensures __all__ exports are valid before expensive test splits
  exports-validation:
    name: Exports Validation
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ env.POETRY_VERSION }}
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: >-
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/poetry.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}-${{ env.CACHE_VERSION }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root

      - name: Install project
        run: poetry install --no-interaction

      - name: Validate __all__ exports
        run: poetry run python scripts/validation/validate-all-exports.py

  # Phase 1 validation job - runs in parallel with all other Phase 1 jobs
  # Separate job for validation scripts mypy (not blocking test-parallel)
  # Rationale: These scripts are CI tooling, not core library code
  mypy-validation-scripts:
    name: Mypy Validation Scripts
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ env.POETRY_VERSION }}
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: >-
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/poetry.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}-${{ env.CACHE_VERSION }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root

      - name: Install project
        run: poetry install --no-interaction

      - name: Run mypy on architectural validation scripts (strict)
        run: |
          poetry run mypy --strict \
            scripts/validation/validate-no-direct-io.py \
            scripts/validation/validate-all-exports.py \
            scripts/validation/validate-no-infra-imports.py \
            scripts/check_transport_imports.py

      # CRITICAL: Transport Import Validation (B+ Hybrid Mode)
      # This step enforces dependency inversion architecture by preventing omnibase_core
      # from importing transport-layer modules (kafka, redis, etc.).
      #
      # Mode selection:
      #   - Feature branches: Changed-files mode (fast ~15s feedback)
      #   - Protected branches (main/develop): Full scan mode (comprehensive validation)
      #
      # WARNING: Do not modify the branch detection logic without understanding RISK-009.
      # See: docs/architecture/decisions/RISK-009-ci-workflow-modification-risk.md
      - name: Check for transport import violations (OMN-220)
        id: transport-check
        run: |
          set +e  # Don't exit on first error, capture results

          # Determine what checks to run
          RUN_CHANGED_FILES="false"
          RUN_FULL_SCAN="false"

          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            if [[ "${{ github.base_ref }}" == "main" || "${{ github.base_ref }}" == "develop" ]]; then
              # PR to protected branch: full scan only (changed-files is redundant)
              RUN_FULL_SCAN="true"
              echo "=== Transport Import Check (Full Scan - PR to ${{ github.base_ref }}) ==="
            else
              # PR to non-protected branch: changed files only (fast feedback)
              RUN_CHANGED_FILES="true"
              echo "=== Transport Import Check (Changed Files - PR to ${{ github.base_ref }}) ==="
            fi
          elif [[ "${{ github.event_name }}" == "push" ]]; then
            # Only full scan on pushes to protected branches
            if [[ "${{ github.ref }}" == "refs/heads/main" || "${{ github.ref }}" == "refs/heads/develop" ]]; then
              RUN_FULL_SCAN="true"
              echo "=== Transport Import Check (Full Scan - Push to ${GITHUB_REF#refs/heads/}) ==="
            else
              # Push to non-protected branch: changed files only
              RUN_CHANGED_FILES="true"
              echo "=== Transport Import Check (Changed Files - Push to ${GITHUB_REF#refs/heads/}) ==="
            fi
          fi

          CHANGED_FILES_EXIT=0
          FULL_SCAN_EXIT=0

          if [[ "$RUN_CHANGED_FILES" == "true" ]]; then
            poetry run python scripts/check_transport_imports.py --changed-files --verbose
            CHANGED_FILES_EXIT=$?
          fi

          if [[ "$RUN_FULL_SCAN" == "true" ]]; then
            poetry run python scripts/check_transport_imports.py --verbose
            FULL_SCAN_EXIT=$?
          fi

          # Output for summary step
          echo "changed_files_exit=$CHANGED_FILES_EXIT" >> $GITHUB_OUTPUT
          echo "full_scan_exit=$FULL_SCAN_EXIT" >> $GITHUB_OUTPUT
          echo "run_changed_files=$RUN_CHANGED_FILES" >> $GITHUB_OUTPUT
          echo "run_full_scan=$RUN_FULL_SCAN" >> $GITHUB_OUTPUT

          # Restore strict mode
          set -e

          # Fail if any check found violations
          if [[ $CHANGED_FILES_EXIT -ne 0 ]] || [[ $FULL_SCAN_EXIT -ne 0 ]]; then
            echo ""
            echo "Transport import violations detected!"
            exit 1
          fi

          echo ""
          echo "All transport import checks passed."

      - name: Transport check summary
        if: always()
        run: |
          echo "## Transport Import Validation (OMN-220)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          RUN_CHANGED="${{ steps.transport-check.outputs.run_changed_files }}"
          RUN_FULL="${{ steps.transport-check.outputs.run_full_scan }}"
          CHANGED_EXIT="${{ steps.transport-check.outputs.changed_files_exit }}"
          FULL_EXIT="${{ steps.transport-check.outputs.full_scan_exit }}"

          if [[ "$RUN_CHANGED" == "true" ]]; then
            if [[ "$CHANGED_EXIT" == "0" ]]; then
              echo "- Changed files check: Passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "- Changed files check: **Failed** (exit code: $CHANGED_EXIT)" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "- Changed files check: Skipped (targeting protected branch)" >> $GITHUB_STEP_SUMMARY
          fi

          if [[ "$RUN_FULL" == "true" ]]; then
            if [[ "$FULL_EXIT" == "0" ]]; then
              echo "- Full scan: Passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "- Full scan: **Failed** (exit code: $FULL_EXIT)" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "- Full scan: Skipped (not targeting protected branch)" >> $GITHUB_STEP_SUMMARY
          fi

  # Phase 1 validation job - runs in parallel with all other Phase 1 jobs
  # Core-Infra Boundary Validation (ADR-005)
  # Enforces that omnibase_core has no direct transport/I/O library imports
  # Complements the Python-based check in mypy-validation-scripts with a simple grep scan
  core-infra-boundary:
    name: Core-Infra Boundary
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate No Transport Imports (ADR-005)
        run: |
          chmod +x ./scripts/validate-no-transport-imports.sh
          ./scripts/validate-no-transport-imports.sh

      - name: Core-Infra boundary summary
        if: always()
        run: |
          echo "## Core-Infra Boundary Validation (ADR-005)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Validates that omnibase_core has no direct transport/I/O imports:" >> $GITHUB_STEP_SUMMARY
          echo "- No HTTP clients (aiohttp, httpx, requests, urllib3)" >> $GITHUB_STEP_SUMMARY
          echo "- No Kafka clients (kafka-python, aiokafka, confluent-kafka)" >> $GITHUB_STEP_SUMMARY
          echo "- No Redis clients (redis, aioredis)" >> $GITHUB_STEP_SUMMARY
          echo "- No Database clients (asyncpg, psycopg2, aiomysql)" >> $GITHUB_STEP_SUMMARY
          echo "- No Message queues (pika, kombu, celery)" >> $GITHUB_STEP_SUMMARY
          echo "- No gRPC or WebSocket libraries" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "See: docs/architecture/decisions/ADR-005-core-infra-dependency-boundary.md" >> $GITHUB_STEP_SUMMARY

  # Phase 1 validation job - runs in parallel with all other Phase 1 jobs
  # Quick documentation check (not blocking test-parallel)
  # Rationale: Doc link validation is independent of code correctness
  docs-validation:
    name: Documentation Validation
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Validate documentation links
        run: |
          python3 scripts/validation/validate-doc-links.py --fix-case

      - name: Documentation validation summary
        if: always()
        run: |
          echo "## Documentation Validation" >> $GITHUB_STEP_SUMMARY
          echo "✅ All documentation links validated" >> $GITHUB_STEP_SUMMARY

  # Phase 1 validation job - runs in parallel with all other Phase 1 jobs
  # Node Purity Validation (OMN-203) - not blocking test-parallel
  # Rationale: Currently non-blocking (continue-on-error: true) due to tech debt
  # Ensures declarative nodes (COMPUTE, REDUCER) maintain purity guarantees
  node-purity-check:
    name: Node Purity Check
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ env.POETRY_VERSION }}
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: >-
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/poetry.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}-${{ env.CACHE_VERSION }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root

      - name: Install project
        run: poetry install --no-interaction

      - name: Run Node Purity Check
        run: |
          # Node Purity Check (OMN-203)
          # Validates declarative nodes (COMPUTE, REDUCER) maintain purity guarantees
          # TECH DEBT NOTE: Existing 'Any' type violations in node_compute.py and node_reducer.py
          # are tracked tech debt. Once fixed, remove --continue-on-error and make blocking.
          poetry run python scripts/check_node_purity.py --verbose
        continue-on-error: true  # Non-blocking until tech debt resolved

      - name: Node purity check summary
        if: always()
        run: |
          echo "## Node Purity Validation (OMN-203)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Validates that declarative nodes (COMPUTE, REDUCER) maintain purity:" >> $GITHUB_STEP_SUMMARY
          echo "- No I/O operations or network calls" >> $GITHUB_STEP_SUMMARY
          echo "- No forbidden imports (networking, subprocess, threading)" >> $GITHUB_STEP_SUMMARY
          echo "- No class-level mutable state" >> $GITHUB_STEP_SUMMARY
          echo "- No caching decorators that introduce state" >> $GITHUB_STEP_SUMMARY

  # Phase 1 validation job - runs in parallel with all other Phase 1 jobs
  # Enum Governance Validation (OMN-1313)
  # Ensures all enums follow architectural standards:
  # - Centralized in src/omnibase_core/enums/
  # - Single responsibility per enum
  # - Use StrValueHelper for string serialization
  enum-governance:
    name: Enum Governance Check
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ env.POETRY_VERSION }}
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: >-
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/poetry.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}-${{ env.CACHE_VERSION }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root

      - name: Install project
        run: poetry install --no-interaction

      - name: Run enum governance validator
        run: poetry run python -m omnibase_core.validation.checker_enum_governance src/omnibase_core/

      - name: Enum governance summary
        if: always()
        run: |
          echo "## Enum Governance Validation (OMN-1313)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Validates enum governance with three rules:" >> $GITHUB_STEP_SUMMARY
          echo "- ENUM_001: Enforce UPPER_SNAKE_CASE naming for enum members" >> $GITHUB_STEP_SUMMARY
          echo "- ENUM_002: Detect Literal type aliases that should be enums" >> $GITHUB_STEP_SUMMARY
          echo "- ENUM_003: Detect duplicate enum values across files (warn-only)" >> $GITHUB_STEP_SUMMARY

  # ============================================================================
  # Tests Gate (aggregator for branch protection)
  # Required check: "Tests Gate" — do not rename without updating branch protection
  # and .github/required-checks.yaml
  # ============================================================================
  tests-gate:
    name: Tests Gate
    runs-on: ubuntu-latest
    needs: [test-parallel]
    if: always()
    steps:
      - name: Check test results
        env:
          TESTS_RESULT: ${{ needs.test-parallel.result }}
        run: |
          if [ "$TESTS_RESULT" != "success" ]; then
            echo "::error::One or more test splits failed, were cancelled, or were skipped"
            echo "Test matrix result: $TESTS_RESULT"
            exit 1
          fi
          echo "All test splits passed (result: $TESTS_RESULT)"

  # Phase 3 - Aggregation job
  # Waits for ALL jobs (Phase 1 validation + Phase 2 tests) to complete
  # Provides unified pass/fail status for branch protection rules
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test-parallel, tests-gate, lint, pyright, exports-validation, mypy-validation-scripts, core-infra-boundary, docs-validation, node-purity-check, enum-governance]
    if: always()

    steps:
      - name: Check test results
        env:
          # Required checks (failures cause test-summary to fail)
          RESULT_PARALLEL: ${{ needs.test-parallel.result }}
          RESULT_TESTS_GATE: ${{ needs.tests-gate.result }}
          RESULT_LINT: ${{ needs.lint.result }}
          RESULT_PYRIGHT: ${{ needs.pyright.result }}
          RESULT_EXPORTS: ${{ needs.exports-validation.result }}
          RESULT_MYPY_SCRIPTS: ${{ needs.mypy-validation-scripts.result }}
          RESULT_CORE_INFRA: ${{ needs.core-infra-boundary.result }}
          RESULT_ENUM_GOV: ${{ needs.enum-governance.result }}
          # Excluded checks (informational only, per .github/required-checks.yaml)
          # Kept in needs: for visibility in summary output, but failures here
          # do NOT block merging or cause test-summary to fail.
          RESULT_DOCS: ${{ needs.docs-validation.result }}
          RESULT_PURITY: ${{ needs.node-purity-check.result }}
        run: |
          echo "=== Required Checks ==="
          echo "Parallel Tests (20 splits): $RESULT_PARALLEL"
          echo "Tests Gate: $RESULT_TESTS_GATE"
          echo "Code Quality: $RESULT_LINT"
          echo "Pyright Type Checking: $RESULT_PYRIGHT"
          echo "Exports Validation: $RESULT_EXPORTS"
          echo "Mypy Validation Scripts: $RESULT_MYPY_SCRIPTS"
          echo "Core-Infra Boundary: $RESULT_CORE_INFRA"
          echo "Enum Governance: $RESULT_ENUM_GOV"

          echo ""
          echo "=== Excluded Checks (informational, non-blocking) ==="
          echo "Documentation Validation: $RESULT_DOCS"
          echo "Node Purity Check: $RESULT_PURITY"

          # Warn on excluded check failures (do not affect exit code)
          if [[ "$RESULT_DOCS" != "success" ]]; then
            echo "::warning::Documentation Validation did not succeed (result: $RESULT_DOCS) — non-blocking per required-checks.yaml"
          fi
          if [[ "$RESULT_PURITY" != "success" ]]; then
            echo "::warning::Node Purity Check did not succeed (result: $RESULT_PURITY) — non-blocking per required-checks.yaml"
          fi

          # Only required checks determine pass/fail
          if [[ "$RESULT_PARALLEL" == "success" ]] && \
             [[ "$RESULT_TESTS_GATE" == "success" ]] && \
             [[ "$RESULT_LINT" == "success" ]] && \
             [[ "$RESULT_PYRIGHT" == "success" ]] && \
             [[ "$RESULT_EXPORTS" == "success" ]] && \
             [[ "$RESULT_MYPY_SCRIPTS" == "success" ]] && \
             [[ "$RESULT_CORE_INFRA" == "success" ]] && \
             [[ "$RESULT_ENUM_GOV" == "success" ]]; then
            echo ""
            echo "All required checks passed."
            exit 0
          else
            echo ""
            echo "::error::One or more required checks failed — see details above."
            exit 1
          fi
