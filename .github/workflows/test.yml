name: Test Suite

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

# Prevent auto-cancellation of running workflows when new commits are pushed
# This ensures test splits actually run to completion instead of being skipped
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

env:
  POETRY_VERSION: "2.2.1"
  PYTHON_VERSION: "3.12"
  CACHE_VERSION: "0.1.5"

jobs:
  # =============================================================================
  # JOB ORDERING RATIONALE (Fail-Fast Optimization)
  # =============================================================================
  #
  # Phase 1 - Quick Validation (parallel, ~2-3 min):
  #   - lint: Code quality (ruff format, ruff check, mypy strict)
  #   - pyright: Type checking (complementary to mypy)
  #   - exports-validation: __all__ exports validation
  #   - docs-validation: Documentation link validation
  #   - node-purity-check: Declarative node purity guarantees
  #   - mypy-validation-scripts: Type check validation scripts
  #   - core-infra-boundary: Transport/I/O import validation (ADR-005)
  #   - enum-governance: Enum architectural standards validation (OMN-1313)
  #   - detect-secrets: Baseline security scan (detect-secrets)
  #
  # Phase 1.5 - Quality Gate:
  #   - quality-gate: Aggregates all Phase 1 quality checks into single gate
  #     This is the API-stable check_name for branch protection
  #
  # Phase 2 - Full Test Suite (after quality-gate passes):
  #   - test-parallel: 20 splits of full test suite (~3 min each)
  #     Depends on: quality-gate
  #     This ensures type errors and lint failures are caught BEFORE
  #     spawning 20 parallel test runners (saves ~60 runner-minutes on failure)
  #
  # Phase 3 - Gates and Summary:
  #   - tests-gate: Aggregates 20-shard test matrix results (API-stable gate)
  #   - ci-summary: Final aggregator for all gates
  #
  # This ordering ensures:
  #   1. Fast feedback on code quality issues (type errors, lint, exports)
  #   2. No wasted compute on test splits when validation fails
  #   3. All Phase 1 jobs run in parallel for speed
  #   4. Branch protection uses stable gate names (Quality Gate, Tests Gate)
  # =============================================================================

  # ---------------------------------------------------------------------------
  # Phase 1 - Quick Validation Jobs (all run in parallel)
  # ---------------------------------------------------------------------------

  # Phase 1 validation job - runs in parallel with pyright, exports-validation
  # Must complete before test-parallel starts (fail-fast optimization)
  lint:
    name: Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ env.POETRY_VERSION }}
          virtualenvs-create: true
          virtualenvs-in-project: true

      # Note: omnibase_spi is now public - no auth required

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: >-
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/poetry.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}-${{ env.CACHE_VERSION }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root

      - name: Install project
        run: poetry install --no-interaction

      - name: Check ruff formatting
        run: poetry run ruff format --check src/ tests/

      - name: Check ruff linting (includes import sorting)
        run: poetry run ruff check src/ tests/

      - name: Run mypy type checking (strict)
        run: poetry run mypy src/omnibase_core

  # Phase 1 validation job - runs in parallel with lint, exports-validation
  # Must complete before test-parallel starts (fail-fast optimization)
  # Pyright complements mypy (in lint job) - catches different type error categories
  pyright:
    name: Pyright Type Checking
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ env.POETRY_VERSION }}
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: >-
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/poetry.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}-${{ env.CACHE_VERSION }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root

      - name: Install project
        run: poetry install --no-interaction

      - name: Run pyright type checking
        run: poetry run pyright src/omnibase_core

  # Phase 1 validation job - runs in parallel with lint, pyright
  # Must complete before test-parallel starts (fail-fast optimization)
  # Quick check (~5 min) ensures __all__ exports are valid before expensive test splits
  exports-validation:
    name: Exports Validation
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ env.POETRY_VERSION }}
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: >-
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/poetry.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}-${{ env.CACHE_VERSION }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root

      - name: Install project
        run: poetry install --no-interaction

      - name: Validate __all__ exports
        run: poetry run python scripts/validation/validate-all-exports.py

  # Phase 1 validation job - runs in parallel with all other Phase 1 jobs
  # Separate job for validation scripts mypy (not blocking test-parallel)
  # Rationale: These scripts are CI tooling, not core library code
  mypy-validation-scripts:
    name: Mypy Validation Scripts
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ env.POETRY_VERSION }}
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: >-
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/poetry.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}-${{ env.CACHE_VERSION }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root

      - name: Install project
        run: poetry install --no-interaction

      - name: Run mypy on architectural validation scripts (strict)
        run: |
          poetry run mypy --strict \
            scripts/validation/validate-no-direct-io.py \
            scripts/validation/validate-all-exports.py \
            scripts/validation/validate-no-infra-imports.py \
            scripts/check_transport_imports.py

      # CRITICAL: Transport Import Validation (B+ Hybrid Mode)
      # This step enforces dependency inversion architecture by preventing omnibase_core
      # from importing transport-layer modules (kafka, redis, etc.).
      #
      # Mode selection:
      #   - Feature branches: Changed-files mode (fast ~15s feedback)
      #   - Protected branches (main/develop): Full scan mode (comprehensive validation)
      #
      # WARNING: Do not modify the branch detection logic without understanding RISK-009.
      # See: docs/decisions/RISK-009-ci-workflow-modification-risk.md
      - name: Check for transport import violations (OMN-220)
        id: transport-check
        run: |
          set +e  # Don't exit on first error, capture results

          # Determine what checks to run
          RUN_CHANGED_FILES="false"
          RUN_FULL_SCAN="false"

          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            if [[ "${{ github.base_ref }}" == "main" || "${{ github.base_ref }}" == "develop" ]]; then
              # PR to protected branch: full scan only (changed-files is redundant)
              RUN_FULL_SCAN="true"
              echo "=== Transport Import Check (Full Scan - PR to ${{ github.base_ref }}) ==="
            else
              # PR to non-protected branch: changed files only (fast feedback)
              RUN_CHANGED_FILES="true"
              echo "=== Transport Import Check (Changed Files - PR to ${{ github.base_ref }}) ==="
            fi
          elif [[ "${{ github.event_name }}" == "push" ]]; then
            # Only full scan on pushes to protected branches
            if [[ "${{ github.ref }}" == "refs/heads/main" || "${{ github.ref }}" == "refs/heads/develop" ]]; then
              RUN_FULL_SCAN="true"
              echo "=== Transport Import Check (Full Scan - Push to ${GITHUB_REF#refs/heads/}) ==="
            else
              # Push to non-protected branch: changed files only
              RUN_CHANGED_FILES="true"
              echo "=== Transport Import Check (Changed Files - Push to ${GITHUB_REF#refs/heads/}) ==="
            fi
          fi

          CHANGED_FILES_EXIT=0
          FULL_SCAN_EXIT=0

          if [[ "$RUN_CHANGED_FILES" == "true" ]]; then
            poetry run python scripts/check_transport_imports.py --changed-files --verbose
            CHANGED_FILES_EXIT=$?
          fi

          if [[ "$RUN_FULL_SCAN" == "true" ]]; then
            poetry run python scripts/check_transport_imports.py --verbose
            FULL_SCAN_EXIT=$?
          fi

          # Output for summary step
          echo "changed_files_exit=$CHANGED_FILES_EXIT" >> $GITHUB_OUTPUT
          echo "full_scan_exit=$FULL_SCAN_EXIT" >> $GITHUB_OUTPUT
          echo "run_changed_files=$RUN_CHANGED_FILES" >> $GITHUB_OUTPUT
          echo "run_full_scan=$RUN_FULL_SCAN" >> $GITHUB_OUTPUT

          # Restore strict mode
          set -e

          # Fail if any check found violations
          if [[ $CHANGED_FILES_EXIT -ne 0 ]] || [[ $FULL_SCAN_EXIT -ne 0 ]]; then
            echo ""
            echo "Transport import violations detected!"
            exit 1
          fi

          echo ""
          echo "All transport import checks passed."

      - name: Transport check summary
        if: always()
        run: |
          echo "## Transport Import Validation (OMN-220)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          RUN_CHANGED="${{ steps.transport-check.outputs.run_changed_files }}"
          RUN_FULL="${{ steps.transport-check.outputs.run_full_scan }}"
          CHANGED_EXIT="${{ steps.transport-check.outputs.changed_files_exit }}"
          FULL_EXIT="${{ steps.transport-check.outputs.full_scan_exit }}"

          if [[ "$RUN_CHANGED" == "true" ]]; then
            if [[ "$CHANGED_EXIT" == "0" ]]; then
              echo "- Changed files check: Passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "- Changed files check: **Failed** (exit code: $CHANGED_EXIT)" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "- Changed files check: Skipped (targeting protected branch)" >> $GITHUB_STEP_SUMMARY
          fi

          if [[ "$RUN_FULL" == "true" ]]; then
            if [[ "$FULL_EXIT" == "0" ]]; then
              echo "- Full scan: Passed" >> $GITHUB_STEP_SUMMARY
            else
              echo "- Full scan: **Failed** (exit code: $FULL_EXIT)" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "- Full scan: Skipped (not targeting protected branch)" >> $GITHUB_STEP_SUMMARY
          fi

  # Phase 1 validation job - runs in parallel with all other Phase 1 jobs
  # Core-Infra Boundary Validation (ADR-005)
  # Enforces that omnibase_core has no direct transport/I/O library imports
  # Complements the Python-based check in mypy-validation-scripts with a simple grep scan
  core-infra-boundary:
    name: Core-Infra Boundary
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate No Transport Imports (ADR-005)
        run: |
          chmod +x ./scripts/validate-no-transport-imports.sh
          ./scripts/validate-no-transport-imports.sh

      - name: Core-Infra boundary summary
        if: always()
        run: |
          echo "## Core-Infra Boundary Validation (ADR-005)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Validates that omnibase_core has no direct transport/I/O imports:" >> $GITHUB_STEP_SUMMARY
          echo "- No HTTP clients (aiohttp, httpx, requests, urllib3)" >> $GITHUB_STEP_SUMMARY
          echo "- No Kafka clients (kafka-python, aiokafka, confluent-kafka)" >> $GITHUB_STEP_SUMMARY
          echo "- No Redis clients (redis, aioredis)" >> $GITHUB_STEP_SUMMARY
          echo "- No Database clients (asyncpg, psycopg2, aiomysql)" >> $GITHUB_STEP_SUMMARY
          echo "- No Message queues (pika, kombu, celery)" >> $GITHUB_STEP_SUMMARY
          echo "- No gRPC or WebSocket libraries" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "See: docs/decisions/ADR-005-core-infra-dependency-boundary.md" >> $GITHUB_STEP_SUMMARY

  # Phase 1 validation job - runs in parallel with all other Phase 1 jobs
  # Quick documentation check (not blocking test-parallel)
  # Rationale: Doc link validation is independent of code correctness
  docs-validation:
    name: Documentation Validation
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Validate documentation links
        id: validate-doc-links
        run: |
          python3 scripts/validation/validate-doc-links.py --fix-case

      - name: Documentation validation summary
        if: always()
        run: |
          echo "## Documentation Validation" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.validate-doc-links.outcome }}" = "success" ]; then
            echo "All documentation links validated successfully" >> $GITHUB_STEP_SUMMARY
          else
            echo "Documentation link validation failed - check logs above for details" >> $GITHUB_STEP_SUMMARY
          fi

  # Phase 1 validation job - runs in parallel with all other Phase 1 jobs
  # Node Purity Validation (OMN-203) - not blocking test-parallel
  # Rationale: Currently non-blocking (continue-on-error: true) due to tech debt
  # Ensures declarative nodes (COMPUTE, REDUCER) maintain purity guarantees
  node-purity-check:
    name: Node Purity Check
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ env.POETRY_VERSION }}
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: >-
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/poetry.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}-${{ env.CACHE_VERSION }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root

      - name: Install project
        run: poetry install --no-interaction

      - name: Run Node Purity Check
        run: |
          # Node Purity Check (OMN-203)
          # Validates declarative nodes (COMPUTE, REDUCER) maintain purity guarantees
          # TECH DEBT NOTE: Existing 'Any' type violations in node_compute.py and node_reducer.py
          # are tracked tech debt. Once fixed, remove --continue-on-error and make blocking.
          poetry run python scripts/check_node_purity.py --verbose
        continue-on-error: true  # Non-blocking until tech debt resolved

      - name: Node purity check summary
        if: always()
        run: |
          echo "## Node Purity Validation (OMN-203)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Validates that declarative nodes (COMPUTE, REDUCER) maintain purity:" >> $GITHUB_STEP_SUMMARY
          echo "- No I/O operations or network calls" >> $GITHUB_STEP_SUMMARY
          echo "- No forbidden imports (networking, subprocess, threading)" >> $GITHUB_STEP_SUMMARY
          echo "- No class-level mutable state" >> $GITHUB_STEP_SUMMARY
          echo "- No caching decorators that introduce state" >> $GITHUB_STEP_SUMMARY

  # Phase 1 validation job - runs in parallel with all other Phase 1 jobs
  # Enum Governance Validation (OMN-1313)
  # Ensures all enums follow architectural standards:
  # - Centralized in src/omnibase_core/enums/
  # - Single responsibility per enum
  # - Use StrValueHelper for string serialization
  enum-governance:
    name: Enum Governance Check
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ env.POETRY_VERSION }}
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: >-
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/poetry.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}-${{ env.CACHE_VERSION }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root

      - name: Install project
        run: poetry install --no-interaction

      - name: Run enum governance validator
        run: poetry run python -m omnibase_core.validation.checker_enum_governance src/omnibase_core/

      - name: Enum governance summary
        if: always()
        run: |
          echo "## Enum Governance Validation (OMN-1313)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Validates enum governance with three rules:" >> $GITHUB_STEP_SUMMARY
          echo "- ENUM_001: Enforce UPPER_SNAKE_CASE naming for enum members" >> $GITHUB_STEP_SUMMARY
          echo "- ENUM_002: Detect Literal type aliases that should be enums" >> $GITHUB_STEP_SUMMARY
          echo "- ENUM_003: Detect duplicate enum values across files (warn-only)" >> $GITHUB_STEP_SUMMARY

  # Phase 1 validation job - runs in parallel with all other Phase 1 jobs
  # Baseline security scan using detect-secrets (OMN-2226)
  # Uses detect-secrets-hook for proper baseline comparison (handles type+hash equality)
  detect-secrets:
    name: Detect Secrets
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install detect-secrets
        run: pip install detect-secrets==1.5.0

      - name: Run detect-secrets-hook
        run: |
          # Use detect-secrets-hook with baseline for proper CI enforcement.
          # detect-secrets-hook compares findings against the baseline using the
          # full equality model (hashed_secret + type), and exits non-zero only
          # for NEW secrets not already baselined.
          #
          # Excludes: poetry.lock (dependency hashes), .venv/, test fixtures,
          # .git/, .secrets.baseline (contains hashed values that self-trigger),
          # workflow YAML (references "secret" in config context)
          set +e
          git ls-files -z | xargs -0 detect-secrets-hook \
            --baseline .secrets.baseline \
            --exclude-files 'poetry\.lock' \
            --exclude-files '\.venv/' \
            --exclude-files 'tests/fixtures/' \
            --exclude-files '\.git/' \
            --exclude-files '\.secrets\.baseline' \
            --exclude-files '\.github/workflows/.*\.yml'
          HOOK_EXIT=$?
          set -e

          if [[ $HOOK_EXIT -eq 0 ]]; then
            echo "## Secrets Scan" >> $GITHUB_STEP_SUMMARY
            echo "No new secrets detected (all findings are baselined)." >> $GITHUB_STEP_SUMMARY
          else
            echo "## New Secrets Detected" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "detect-secrets-hook found secrets not present in .secrets.baseline." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "If these are false positives, regenerate the baseline:" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo 'detect-secrets scan --all-files --exclude-files "poetry\.lock" --exclude-files "\.venv/" --exclude-files "tests/fixtures/" --exclude-files "\.git/" --exclude-files "\.secrets\.baseline" --exclude-files "\.github/workflows/.*\.yml" --force-use-all-plugins > .secrets.baseline' >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

  # ---------------------------------------------------------------------------
  # Phase 1.5 - Quality Gate (aggregates all Phase 1 quality checks)
  # ---------------------------------------------------------------------------
  # API-STABLE check_name: "Quality Gate"
  # This is the single required check for branch protection (replaces 6+ individual checks).
  # Individual Phase 1 job names can change without updating branch protection rules.
  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [lint, pyright, exports-validation, mypy-validation-scripts, core-infra-boundary, docs-validation, node-purity-check, enum-governance, detect-secrets]
    if: always()

    steps:
      - name: Evaluate quality checks
        run: |
          echo "## Quality Gate Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          lint="${{ needs.lint.result }}"
          pyright="${{ needs.pyright.result }}"
          exports="${{ needs.exports-validation.result }}"
          mypy_scripts="${{ needs.mypy-validation-scripts.result }}"
          core_infra="${{ needs.core-infra-boundary.result }}"
          docs="${{ needs.docs-validation.result }}"
          purity="${{ needs.node-purity-check.result }}"
          enum_gov="${{ needs.enum-governance.result }}"
          secrets="${{ needs.detect-secrets.result }}"

          # Report each check
          echo "| Check | Result |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Code Quality (lint) | $lint |" >> $GITHUB_STEP_SUMMARY
          echo "| Pyright Type Checking | $pyright |" >> $GITHUB_STEP_SUMMARY
          echo "| Exports Validation | $exports |" >> $GITHUB_STEP_SUMMARY
          echo "| Mypy Validation Scripts | $mypy_scripts |" >> $GITHUB_STEP_SUMMARY
          echo "| Core-Infra Boundary | $core_infra |" >> $GITHUB_STEP_SUMMARY
          echo "| Documentation Validation | $docs |" >> $GITHUB_STEP_SUMMARY
          echo "| Node Purity Check | $purity |" >> $GITHUB_STEP_SUMMARY
          echo "| Enum Governance | $enum_gov |" >> $GITHUB_STEP_SUMMARY
          echo "| Detect Secrets | $secrets |" >> $GITHUB_STEP_SUMMARY

          # Gate logic: all must pass
          # Note: node-purity-check is non-blocking (continue-on-error) â€” reported for visibility only
          if [[ "$lint" == "success" ]] && \
             [[ "$pyright" == "success" ]] && \
             [[ "$exports" == "success" ]] && \
             [[ "$mypy_scripts" == "success" ]] && \
             [[ "$core_infra" == "success" ]] && \
             [[ "$docs" == "success" ]] && \
             [[ "$enum_gov" == "success" ]] && \
             [[ "$secrets" == "success" ]]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Quality Gate: PASSED**" >> $GITHUB_STEP_SUMMARY
            echo "All quality checks passed."
            exit 0
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Quality Gate: FAILED**" >> $GITHUB_STEP_SUMMARY
            echo "Quality gate failed. See individual check results above."
            exit 1
          fi

  # ---------------------------------------------------------------------------
  # Phase 2 - Full Test Suite
  # ---------------------------------------------------------------------------

  # Parallel test execution - split into 20 groups for speed and memory management
  # Split strategy rationale:
  #   - 12,198 total tests / 20 splits = ~610 tests/split
  #   - Target: 1.5-3 minutes per split (prevents runner timeouts/cancellations)
  #   - 20x parallelization speedup vs sequential execution
  #   - Increased from 16 to 20 splits to eliminate Split 10 timeout issues
  #   - Shorter per-split runtime reduces probability of external runner shutdown
  #
  # Dependency rationale (fail-fast optimization):
  #   - quality-gate: Aggregates all Phase 1 checks (lint, pyright, exports, etc.)
  #   - This ensures quality failures are caught BEFORE spawning 20 test runners
  #   - Saves ~60 runner-minutes on validation failures
  test-parallel:
    name: Tests (Split ${{ matrix.split }}/20)
    needs: [quality-gate]
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        split: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: ${{ env.POETRY_VERSION }}
          virtualenvs-create: true
          virtualenvs-in-project: true

      # Note: omnibase_spi is now public - no auth required

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: >-
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/poetry.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}-${{ env.CACHE_VERSION }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: |
          poetry install --no-interaction --no-root || {
            echo "Dependency install failed"
            exit 1
          }

      - name: Install project
        run: |
          poetry install --no-interaction || {
            echo "Project install failed"
            exit 1
          }

      - name: Run test split ${{ matrix.split }}/20
        run: |
          poetry run pytest tests/ \
            --splits 20 \
            --group ${{ matrix.split }} \
            -n auto \
            --timeout=60 \
            --timeout-method=thread \
            --tb=short \
            --junitxml=junit-${{ matrix.split }}.xml
          # Per-test timeout: 60 seconds prevents infinite hangs
          #   - Longest test: ~30 seconds (2x safety margin)
          #   - Thread method: Avoids signal handler issues in parallel execution
          #   - No false positives observed at this threshold
          # All splits use -n auto (full parallelism) - shorter splits reduce
          # resource pressure and runner cancellation probability
          # Note: Coverage collection disabled - use local pytest-cov for coverage reports

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.split }}
          path: junit-${{ matrix.split }}.xml
          retention-days: 7

  # ---------------------------------------------------------------------------
  # Phase 3 - Gates and Summary
  # ---------------------------------------------------------------------------

  # Tests Gate - aggregates 20-shard test matrix results
  # API-STABLE check_name: "Tests Gate"
  # Shard count can change without updating branch protection rules.
  tests-gate:
    name: Tests Gate
    runs-on: ubuntu-latest
    needs: [test-parallel]
    if: always()

    steps:
      - name: Evaluate test results
        run: |
          echo "## Tests Gate Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          parallel="${{ needs.test-parallel.result }}"

          echo "| Check | Result |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Parallel Tests (20 splits) | $parallel |" >> $GITHUB_STEP_SUMMARY

          if [[ "$parallel" == "success" ]]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Tests Gate: PASSED**" >> $GITHUB_STEP_SUMMARY
            echo "All 20 test splits passed."
            exit 0
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Tests Gate: FAILED**" >> $GITHUB_STEP_SUMMARY
            echo "Test matrix result: $parallel"
            exit 1
          fi

  # CI Summary - final aggregator for all gates (OMN-2226)
  # API-STABLE check_name: "CI Summary"
  # Aggregates Quality Gate + Tests Gate into a single top-level status.
  # Not strictly required for omnibase_core (no path filtering on Tier A gates),
  # but added for uniformity across all OmniNode repos.
  ci-summary:
    name: CI Summary
    runs-on: ubuntu-latest
    needs: [quality-gate, tests-gate]
    if: always()

    steps:
      - name: Evaluate all gates
        run: |
          echo "## CI Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          quality="${{ needs.quality-gate.result }}"
          tests="${{ needs.tests-gate.result }}"

          echo "| Gate | Result |" >> $GITHUB_STEP_SUMMARY
          echo "|------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Quality Gate | $quality |" >> $GITHUB_STEP_SUMMARY
          echo "| Tests Gate | $tests |" >> $GITHUB_STEP_SUMMARY

          if [[ "$quality" == "success" ]] && [[ "$tests" == "success" ]]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**CI Summary: ALL GATES PASSED**" >> $GITHUB_STEP_SUMMARY
            echo "All CI gates passed."
            exit 0
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**CI Summary: FAILED**" >> $GITHUB_STEP_SUMMARY
            echo ""
            echo "Gate results:"
            echo "  Quality Gate: $quality"
            echo "  Tests Gate: $tests"
            exit 1
          fi
