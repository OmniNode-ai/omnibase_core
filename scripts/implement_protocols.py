#!/usr/bin/env python3
"""
Systematic Protocol Implementation Script

This script implements omnibase_spi protocols across all 216 models in the codebase.
Follows ONEX compliance and Phase 3 coordination requirements.
"""

import os
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple


class ProtocolImplementer:
    """Automates protocol implementation across model hierarchy."""

    # Protocol mappings by model category
    PROTOCOL_MAPPINGS = {
        "config": ["Configurable", "Serializable", "Validatable"],
        "metadata": ["MetadataProvider", "Serializable", "Validatable"],
        "operations": ["Executable", "Identifiable", "Serializable", "Validatable"],
        "nodes": ["Identifiable", "MetadataProvider", "Serializable", "Validatable"],
        "core": [
            "Configurable",
            "Serializable",
            "Validatable",
            "Nameable",
        ],  # Core gets all
        "infrastructure": ["Executable", "Configurable", "Serializable"],
        "cli": ["Serializable", "Nameable", "Validatable"],
        "connections": ["Configurable", "Validatable", "Serializable"],
        "utils": ["Serializable", "Validatable"],
        "common": ["Serializable", "Validatable"],
        "validation": ["Validatable", "Serializable"],
        "fsm": ["Executable", "Serializable", "Validatable"],
        "contracts": ["Validatable", "Serializable"],
    }

    # Protocol method templates
    PROTOCOL_METHODS = {
        "Configurable": '''
    def configure(self, **kwargs: Any) -> bool:
        """Configure instance with provided parameters (Configurable protocol)."""
        try:
            for key, value in kwargs.items():
                if hasattr(self, key):
                    setattr(self, key, value)
            return True
        except Exception:
            return False''',
        "Executable": '''
    def execute(self, **kwargs: Any) -> bool:
        """Execute or update execution status (Executable protocol)."""
        try:
            # Update any relevant execution fields
            for key, value in kwargs.items():
                if hasattr(self, key):
                    setattr(self, key, value)
            return True
        except Exception:
            return False''',
        "Identifiable": '''
    def get_id(self) -> str:
        """Get unique identifier (Identifiable protocol)."""
        # Try common ID field patterns
        for field in ['id', 'uuid', 'identifier', 'node_id', 'execution_id', 'metadata_id']:
            if hasattr(self, field):
                value = getattr(self, field)
                if value is not None:
                    return str(value)
        return f"{self.__class__.__name__}_{id(self)}"''',
        "MetadataProvider": '''
    def get_metadata(self) -> dict[str, Any]:
        """Get metadata as dictionary (MetadataProvider protocol)."""
        metadata = {}
        # Include common metadata fields
        for field in ['name', 'description', 'version', 'tags', 'metadata']:
            if hasattr(self, field):
                value = getattr(self, field)
                if value is not None:
                    metadata[field] = str(value) if not isinstance(value, (dict, list)) else value
        return metadata

    def set_metadata(self, metadata: dict[str, Any]) -> bool:
        """Set metadata from dictionary (MetadataProvider protocol)."""
        try:
            for key, value in metadata.items():
                if hasattr(self, key):
                    setattr(self, key, value)
            return True
        except Exception:
            return False''',
        "Nameable": '''
    def get_name(self) -> str:
        """Get name (Nameable protocol)."""
        # Try common name field patterns
        for field in ['name', 'display_name', 'title', 'node_name']:
            if hasattr(self, field):
                value = getattr(self, field)
                if value is not None:
                    return str(value)
        return f"Unnamed {self.__class__.__name__}"

    def set_name(self, name: str) -> None:
        """Set name (Nameable protocol)."""
        # Try to set the most appropriate name field
        for field in ['name', 'display_name', 'title', 'node_name']:
            if hasattr(self, field):
                setattr(self, field, name)
                return''',
        "Serializable": '''
    def serialize(self) -> dict[str, Any]:
        """Serialize to dictionary (Serializable protocol)."""
        return self.model_dump(exclude_none=False, by_alias=True)''',
        "Validatable": '''
    def validate(self) -> bool:
        """Validate instance integrity (Validatable protocol)."""
        try:
            # Basic validation - ensure required fields exist
            # Override in specific models for custom validation
            return True
        except Exception:
            return False''',
    }

    def __init__(self, models_dir: str):
        self.models_dir = Path(models_dir)
        self.processed_files: List[str] = []
        self.errors: List[str] = []

    def find_all_models(self) -> Dict[str, List[Path]]:
        """Find all model files categorized by directory."""
        categories = {}

        for model_file in self.models_dir.rglob("model_*.py"):
            # Get category from directory structure
            relative_path = model_file.relative_to(self.models_dir)
            category = (
                relative_path.parts[0] if len(relative_path.parts) > 1 else "unknown"
            )

            if category not in categories:
                categories[category] = []
            categories[category].append(model_file)

        return categories

    def analyze_model_file(self, file_path: Path) -> Tuple[str, List[str], bool]:
        """Analyze model file to determine class name and current protocols."""
        try:
            with open(file_path, "r") as f:
                content = f.read()

            # Find class definition
            class_match = re.search(r"class\s+(\w+)\s*\([^)]+\):", content)
            if not class_match:
                return "", [], False

            class_name = class_match.group(1)

            # Check if already implements protocols
            class_line = class_match.group(0)
            current_protocols = []
            for protocol in self.PROTOCOL_METHODS.keys():
                if protocol in class_line:
                    current_protocols.append(protocol)

            # Check if already has protocol methods
            has_protocol_methods = "# Protocol method implementations" in content

            return class_name, current_protocols, has_protocol_methods

        except Exception as e:
            self.errors.append(f"Error analyzing {file_path}: {e}")
            return "", [], False

    def update_imports(self, content: str, protocols: List[str]) -> str:
        """Add protocol imports if not already present."""
        import_section = """from omnibase_core.core.type_constraints import (
    {protocols}
)"""

        protocols_str = ",\n    ".join(protocols)
        new_import = import_section.format(protocols=protocols_str)

        # Check if type_constraints import already exists
        if "from omnibase_core.core.type_constraints import" in content:
            # Update existing import
            pattern = r"from omnibase_core\.core\.type_constraints import \([^)]+\)"
            return re.sub(
                pattern,
                f"from omnibase_core.core.type_constraints import (\n    {protocols_str}\n)",
                content,
            )
        else:
            # Add new import after pydantic import
            pydantic_pattern = r"(from pydantic import [^\n]+\n)"
            if re.search(pydantic_pattern, content):
                return re.sub(pydantic_pattern, rf"\1\n{new_import}\n", content)
            else:
                # Add after other imports
                return content.replace(
                    "from pydantic import BaseModel",
                    f"from pydantic import BaseModel\n\n{new_import}",
                )

    def update_class_definition(
        self, content: str, class_name: str, protocols: List[str]
    ) -> str:
        """Update class definition to include protocols."""
        # Find the class definition
        class_pattern = rf"class\s+{class_name}\s*\([^)]+\):"
        match = re.search(class_pattern, content)

        if not match:
            return content

        old_class_def = match.group(0)

        # Extract existing inheritance
        inheritance_match = re.search(r"class\s+\w+\s*\(([^)]+)\):", old_class_def)
        if inheritance_match:
            current_inheritance = inheritance_match.group(1).strip()
            # Add protocols to inheritance
            protocols_str = ", ".join(protocols)
            new_inheritance = f"{current_inheritance}, {protocols_str}"
        else:
            # Shouldn't happen with BaseModel, but handle gracefully
            protocols_str = ", ".join(protocols)
            new_inheritance = protocols_str

        new_class_def = f"class {class_name}(\n    {new_inheritance}\n):"

        return content.replace(old_class_def, new_class_def)

    def add_protocol_methods(self, content: str, protocols: List[str]) -> str:
        """Add protocol method implementations."""
        if "# Protocol method implementations" in content:
            return content  # Already has protocol methods

        # Generate protocol methods
        protocol_methods = []
        for protocol in protocols:
            if protocol in self.PROTOCOL_METHODS:
                protocol_methods.append(self.PROTOCOL_METHODS[protocol])

        if not protocol_methods:
            return content

        # Find where to insert methods (before __all__ export)
        methods_section = f"""
    # Protocol method implementations
{''.join(protocol_methods)}
"""

        # Insert before export section
        if "# Export for use" in content:
            return content.replace(
                "# Export for use", f"{methods_section}\n\n# Export for use"
            )
        elif "__all__ = " in content:
            return content.replace("__all__ = ", f"{methods_section}\n\n__all__ = ")
        else:
            # Add at end of file
            return content + methods_section

    def update_class_docstring(
        self, content: str, class_name: str, protocols: List[str]
    ) -> str:
        """Update class docstring to document implemented protocols."""
        protocol_docs = f"""
    Implements omnibase_spi protocols:
{chr(10).join([f'    - {protocol}: {self.get_protocol_description(protocol)}' for protocol in protocols])}
    """

        # Find class docstring
        class_pattern = rf'class\s+{class_name}\s*\([^)]+\):\s*"""([^"]+)"""'
        match = re.search(class_pattern, content, re.DOTALL)

        if match:
            old_docstring = match.group(1)
            if "Implements omnibase_spi protocols:" not in old_docstring:
                new_docstring = old_docstring.rstrip() + protocol_docs
                return content.replace(old_docstring, new_docstring)

        return content

    def get_protocol_description(self, protocol: str) -> str:
        """Get description for protocol."""
        descriptions = {
            "Configurable": "Configuration management capabilities",
            "Executable": "Execution management capabilities",
            "Identifiable": "UUID-based identification",
            "MetadataProvider": "Metadata management capabilities",
            "Nameable": "Name management interface",
            "Serializable": "Data serialization/deserialization",
            "Validatable": "Validation and verification",
        }
        return descriptions.get(protocol, "Protocol interface")

    def implement_protocols_for_file(self, file_path: Path, category: str) -> bool:
        """Implement protocols for a single model file."""
        try:
            # Get protocols for this category
            protocols = self.PROTOCOL_MAPPINGS.get(
                category, ["Serializable", "Validatable"]
            )

            # Analyze current state
            class_name, current_protocols, has_methods = self.analyze_model_file(
                file_path
            )
            if not class_name:
                self.errors.append(f"Could not find class in {file_path}")
                return False

            # Skip if already has all protocols
            if set(protocols).issubset(set(current_protocols)) and has_methods:
                return True

            # Read file content
            with open(file_path, "r") as f:
                content = f.read()

            # Add missing protocols
            missing_protocols = [p for p in protocols if p not in current_protocols]
            if missing_protocols:
                # Update imports
                content = self.update_imports(content, protocols)

                # Update class definition
                content = self.update_class_definition(
                    content, class_name, missing_protocols
                )

                # Update docstring
                content = self.update_class_docstring(content, class_name, protocols)

            # Add protocol methods if not present
            if not has_methods:
                content = self.add_protocol_methods(content, protocols)

            # Write updated content
            with open(file_path, "w") as f:
                f.write(content)

            self.processed_files.append(str(file_path))
            return True

        except Exception as e:
            self.errors.append(f"Error processing {file_path}: {e}")
            return False

    def implement_all_protocols(self) -> Dict[str, int]:
        """Implement protocols across all model categories."""
        categories = self.find_all_models()
        stats = {
            "total_files": 0,
            "processed_files": 0,
            "errors": 0,
            "categories_processed": 0,
        }

        print(
            f"ğŸš€ Starting protocol implementation across {len(categories)} categories"
        )

        for category, files in categories.items():
            print(f"\nğŸ“‚ Processing category: {category} ({len(files)} files)")

            category_success = 0
            for file_path in files:
                stats["total_files"] += 1
                if self.implement_protocols_for_file(file_path, category):
                    stats["processed_files"] += 1
                    category_success += 1
                else:
                    stats["errors"] += 1

            print(f"   âœ… {category_success}/{len(files)} files processed successfully")
            if category_success == len(files):
                stats["categories_processed"] += 1

        return stats

    def generate_report(self, stats: Dict[str, int]) -> str:
        """Generate implementation report."""
        report = f"""
# Protocol Implementation Report

## Summary
- **Total Files**: {stats['total_files']}
- **Successfully Processed**: {stats['processed_files']}
- **Errors**: {stats['errors']}
- **Categories Completed**: {stats['categories_processed']}
- **Success Rate**: {(stats['processed_files'] / stats['total_files'] * 100):.1f}%

## Protocol Mappings Implemented
"""
        for category, protocols in self.PROTOCOL_MAPPINGS.items():
            report += f"- **{category}**: {', '.join(protocols)}\n"

        if self.errors:
            report += f"\n## Errors ({len(self.errors)})\n"
            for error in self.errors:
                report += f"- {error}\n"

        report += f"\n## Processed Files ({len(self.processed_files)})\n"
        for file_path in self.processed_files:
            report += f"- {file_path}\n"

        return report


def main():
    """Main execution function."""
    # Determine models directory
    script_dir = Path(__file__).parent
    models_dir = script_dir.parent / "src" / "omnibase_core" / "models"

    if not models_dir.exists():
        print(f"âŒ Models directory not found: {models_dir}")
        return 1

    print(f"ğŸ¯ Protocol Implementation for omnibase_core")
    print(f"ğŸ“ Models directory: {models_dir}")
    print(f"ğŸ”§ Implementing protocols across 216 models...")

    # Initialize implementer
    implementer = ProtocolImplementer(str(models_dir))

    # Run implementation
    stats = implementer.implement_all_protocols()

    # Generate and save report
    report = implementer.generate_report(stats)
    report_path = script_dir / "protocol_implementation_report.md"
    with open(report_path, "w") as f:
        f.write(report)

    print(f"\nğŸ‰ Protocol implementation completed!")
    print(f"ğŸ“Š Report saved to: {report_path}")
    print(
        f"âœ… {stats['processed_files']}/{stats['total_files']} files processed successfully"
    )

    if stats["errors"] > 0:
        print(f"âš ï¸  {stats['errors']} errors encountered - see report for details")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
